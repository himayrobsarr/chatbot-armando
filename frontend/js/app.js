// app.js - LÃ³gica principal de la aplicaciÃ³n

class AvatarApp {
    constructor() {
        this.sessionId = null;
        this.isRecording = false;
        this.isInitialized = false;
        this.peerConnection = null; 
        
        // Referencias DOM
        this.elements = {
            initBtn: document.getElementById('initBtn'),
            recordBtn: document.getElementById('recordBtn'),
            stopBtn: document.getElementById('stopBtn'),
            recordBtnText: document.getElementById('recordBtnText'),
            statusValue: document.getElementById('statusValue'),
            latencyValue: document.getElementById('latencyValue'),
            videoOverlay: document.getElementById('videoOverlay'),
            avatarVideo: document.getElementById('avatarVideo'),
            debugConsole: document.getElementById('debugConsole')
        };
        
        this.bindEvents();
        this.init();
    }

    // Vincular eventos
    bindEvents() {
        this.elements.initBtn.addEventListener('click', () => this.initializeAvatar());
        
        // Mantener presionado para grabar
        this.elements.recordBtn.addEventListener('mousedown', () => this.startRecording());
        this.elements.recordBtn.addEventListener('mouseup', () => this.stopRecording());
        this.elements.recordBtn.addEventListener('mouseleave', () => {
            if (this.isRecording) this.stopRecording();
        });
        
        // Touch events para mÃ³viles
        this.elements.recordBtn.addEventListener('touchstart', (e) => {
            e.preventDefault();
            this.startRecording();
        });
        this.elements.recordBtn.addEventListener('touchend', (e) => {
            e.preventDefault();
            this.stopRecording();
        });
        
        this.elements.stopBtn.addEventListener('click', () => this.stopSession());
    }

    // InicializaciÃ³n
    async init() {
        this.log('Sistema inicializado. Esperando interacciÃ³n del usuario...');
        
        // Verificar soporte de Speech API
        if (!SpeechManager.isAvailable()) {
            this.log('âŒ Tu navegador no soporta reconocimiento de voz. Usa Chrome, Edge o Safari.', 'error');
            return;
        }
        
        // Configurar eventos de Speech Manager
        SpeechManager.onResult = (text) => this.handleSpeechResult(text);
        SpeechManager.onError = (error) => this.handleSpeechError(error);
        SpeechManager.onStart = () => this.log('ðŸŽ¤ Escuchando...');
        SpeechManager.onEnd = () => this.log('âœ… Escucha finalizada');
        
        // Verificar salud del backend
        try {
            const health = await API.checkHealth();
            if (health.status === 'ok') {
                this.log('âœ… Backend conectado correctamente', 'success');
            } else {
                this.log('âš ï¸ Backend responde pero hay configuraciÃ³n incompleta', 'warning');
            }
        } catch (error) {
            this.log('âŒ No se pudo conectar con el backend. Verifica que estÃ© corriendo en localhost:3000', 'error');
        }
    }

    // Inicializar avatar (MODIFICADA)
    async initializeAvatar() {
        this.log('ðŸš€ Iniciando avatar...');
        this.updateStatus('Inicializando...', 'processing');
        this.elements.initBtn.disabled = true;

        try {
            // 1. Solicitar acceso al micrÃ³fono
            this.log('ðŸŽ¤ Solicitando acceso al micrÃ³fono...');
            await AudioManager.requestMicrophoneAccess();
            this.log('âœ… MicrÃ³fono accesible', 'success');

            // 2. Crear sesiÃ³n Y OBTENER DATOS WebRTC (Paso Ãºnico)
            this.log('ðŸŽ¬ Creando sesiÃ³n con HeyGen (Paso Ãºnico)...');
            const startTime = Date.now();
            
            // sessionData ahora contiene { sessionId: "...", webrtcData: { ... } }
            const sessionData = await API.createHeyGenSession();
            
            // âœ… CORRECTO - Buscar realtime_endpoint
if (!sessionData.sessionId || !sessionData.webrtcData || !sessionData.webrtcData.realtime_endpoint) {
    console.error("Respuesta de /session incompleta:", sessionData);
    throw new Error("El backend no devolviÃ³ sessionId y realtime_endpoint en /session.");
}

            // Guardamos el ID de sesiÃ³n
            this.sessionId = sessionData.sessionId; 
            this.log(`âœ… SesiÃ³n HeyGen creada: ${this.sessionId}`, 'success');
            
            // 3. Configurar WebRTC con los datos recibidos
            this.log('ðŸ”Œ Configurando conexiÃ³n WebRTC...');
            // Pasamos los datos de WebRTC (sdp, server_url, etc.)
            await this.setupWebRTC(sessionData.webrtcData); 
            this.log('âœ… ConexiÃ³n WebRTC establecida.', 'success');

            const latency = Date.now() - startTime;
            this.log(`âœ… SesiÃ³n activada y lista en ${latency}ms`, 'success');
            this.updateLatency(latency);
            
            // 4. Ocultar overlay del video
            this.elements.videoOverlay.classList.add('hidden');

            // 5. Actualizar UI
            this.isInitialized = true;
            this.updateStatus('Listo', 'ready');
            this.elements.recordBtn.disabled = false;
            this.elements.stopBtn.disabled = false;
            this.elements.initBtn.style.display = 'none';
            this.elements.recordBtn.style.display = 'flex';
            
            this.log('âœ… Sistema listo. MantÃ©n presionado el botÃ³n rojo para hablar', 'success');

        } catch (error) {
            this.log(`âŒ Error al inicializar: ${error.message}`, 'error');
            this.updateStatus('Error', 'idle');
            this.elements.initBtn.disabled = false;
        }
    }

    // Iniciar grabaciÃ³n
    startRecording() {
        if (!this.isInitialized || this.isRecording) return;

        this.isRecording = true;
        this.elements.recordBtn.classList.add('recording');
        this.elements.recordBtnText.textContent = 'ðŸ”´ Escuchando...';
        this.updateStatus('Escuchando', 'recording');
        
        SpeechManager.start();
        this.log('ðŸŽ¤ Reconocimiento de voz iniciado');
    }

    // Detener grabaciÃ³n y procesar
    async stopRecording() {
        if (!this.isRecording) return;

        this.isRecording = false;
        this.elements.recordBtn.classList.remove('recording');
        this.elements.recordBtnText.textContent = 'Procesando...';
        this.updateStatus('Procesando', 'processing');
        
        SpeechManager.stop();
        this.log('ðŸ›‘ Reconocimiento de voz detenido');
    }
    
    // FunciÃ³n de WebRTC (sin cambios desde la Ãºltima vez)
// En app.js, REEMPLAZA la funciÃ³n setupWebRTC() por esta:

async setupWebRTC(webrtcData) {
    // Ya NO usamos sdp, usamos el realtime_endpoint
    if (!webrtcData.realtime_endpoint) {
        console.error("Falta realtime_endpoint:", webrtcData);
        throw new Error("HeyGen no devolviÃ³ realtime_endpoint");
    }

    this.log('ðŸ”Œ Conectando via WebSocket a HeyGen...');
    
    // Crear conexiÃ³n WebSocket
    this.ws = new WebSocket(webrtcData.realtime_endpoint);
    
    this.ws.onopen = () => {
        this.log('âœ… WebSocket conectado al avatar', 'success');
    };
    
    this.ws.onmessage = (event) => {
        this.handleAvatarMessage(event);
    };
    
    this.ws.onerror = (error) => {
        this.log('âŒ Error WebSocket: ' + error, 'error');
    };
    
    this.ws.onclose = () => {
        this.log('ðŸ”Œ WebSocket cerrado');
    };

    // Esperar a que conecte
    return new Promise((resolve, reject) => {
        this.ws.onopen = () => {
            this.log('âœ… WebSocket conectado', 'success');
            resolve();
        };
        this.ws.onerror = (error) => {
            reject(error);
        };
    });
}

// Agregar DESPUÃ‰S de setupWebRTC() en app.js

handleAvatarMessage(event) {
    try {
        const data = JSON.parse(event.data);
        
        console.log('ðŸ“© Mensaje del avatar:', data);
        
        switch(data.type) {
            case 'avatar_start_talking':
                this.log('ðŸ—£ï¸ Avatar hablando...', 'success');
                break;
                
            case 'avatar_stop_talking':
                this.log('ðŸ¤ Avatar terminÃ³', 'success');
                break;
                
            case 'stream':
                // Video stream - actualizar video
                if (data.video_url) {
                    this.elements.avatarVideo.src = data.video_url;
                    this.elements.avatarVideo.play();
                }
                break;
                
                case 'error':
                    this.log('âŒ Error avatar: ' + (data.error?.message || JSON.stringify(data.error)), 'error');
                    console.error('Error completo:', data);
                    break;
        }
    } catch (error) {
        console.error('Error procesando mensaje:', error);
    }
}

    // Manejar resultado del reconocimiento de voz (sin cambios)
// REEMPLAZA la parte de HeyGen en handleSpeechResult() por esto:

async handleSpeechResult(text) {
    if (!text || text.trim().length === 0) {
        this.log('âš ï¸ No se detectÃ³ texto', 'warning');
        this.resetRecordButton();
        return;
    }

    this.log(`ðŸ“ Texto detectado: "${text}"`, 'success');

    try {
        // 1. Generar audio con ElevenLabs (mantener igual)
        this.log('ðŸŽ™ï¸ Enviando texto a ElevenLabs...');
        const startTime = Date.now();
        const responseAudio = await API.sendTextToElevenLabs(text);
        const latency = Date.now() - startTime;
        this.log(`âœ… Audio generado en ${latency}ms`, 'success');
        this.updateLatency(latency);
        
        // 2. Enviar a HeyGen VIA WEBSOCKET (NUEVO)
        if (this.ws && this.ws.readyState === WebSocket.OPEN) {
            this.log('ðŸŽ¬ Enviando a avatar via WebSocket...');
            
            const message = {
                type: 'repeat',  // âœ… Cambiar de 'speak' a 'repeat'
                text: text
            };
            
            this.ws.send(JSON.stringify(message));
            this.log('âœ… Lip-sync enviado', 'success');
        } else {
            this.log('âš ï¸ WebSocket no conectado', 'warning');
        }

        // 3. Reproducir audio (mantener igual)
        this.log('ðŸ”Š Reproduciendo respuesta...');
        await AudioManager.playAudio(responseAudio);
        this.log('âœ… Proceso completado', 'success');

    } catch (error) {
        this.log(`âŒ Error: ${error.message}`, 'error');
    } finally {
        this.resetRecordButton();
    }
}

    // Manejar errores del reconocimiento de voz (sin cambios)
    handleSpeechError(error) {
        this.log(`âŒ Error de reconocimiento: ${error}`, 'error');
        this.resetRecordButton();
    }

    // Detener sesiÃ³n (sin cambios)
// REEMPLAZA stopSession() por esto:

stopSession() {
    this.log('ðŸ›‘ Cerrando sesiÃ³n...');
    
    // Cerrar WebSocket en vez de RTCPeerConnection
    if (this.ws) {
        this.ws.close();
        this.ws = null;
        this.log('ðŸ”Œ WebSocket cerrado');
    }
    
    if (this.isRecording) {
        SpeechManager.stop();
    }
    
    AudioManager.cleanup();
    
    this.sessionId = null;
    this.isInitialized = false;
    
    this.updateStatus('Desconectado', 'idle');
    this.elements.initBtn.disabled = false;
    this.elements.recordBtn.disabled = true;
    this.elements.stopBtn.disabled = true;
    this.elements.initBtn.style.display = 'flex';
    this.elements.recordBtn.style.display = 'none';
    this.updateLatency(0);
    
    this.log('âœ… SesiÃ³n cerrada', 'success');
}

    // Helpers (sin cambios)
    resetRecordButton() {
        this.elements.recordBtnText.textContent = 'MantÃ©n presionado para hablar';
        this.updateStatus('Listo', 'ready');
    }

    updateStatus(text, type) {
        const statusClasses = {
            idle: 'status-idle',
            ready: 'status-ready',
            recording: 'status-recording',
            processing: 'status-processing'
        };

        const dot = this.elements.statusValue.querySelector('.status-dot');
        if (dot) {
            dot.className = `status-dot ${statusClasses[type]}`;
        }

        const textNode = this.elements.statusValue.childNodes[2];
        if (textNode) {
            textNode.textContent = text;
        }
    }

    updateLatency(ms) {
        this.elements.latencyValue.textContent = ms > 0 ? `${ms} ms` : '--- ms';
    }

    log(message, type = 'info') {
        const p = document.createElement('p');
        p.className = `console-msg ${type}`;
        p.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
        this.elements.debugConsole.appendChild(p);
        this.elements.debugConsole.scrollTop = this.elements.debugConsole.scrollHeight;
        
        console.log(message);
    }
}

// Inicializar aplicaciÃ³n cuando el DOM estÃ© listo
document.addEventListener('DOMContentLoaded', () => {
    window.app = new AvatarApp();
});